{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Úkol č. 2 - předzpracování dat a binární klasifikace (do 9. listopadu 23:59)\n",
    "\n",
    "  * V rámci tohoto úkolu se musíte vypořádat s příznaky, které jsou různých typů.\n",
    "  * Před tím, než na nich postavíte predikční model, je třeba je nějakým způsobem převést do číselné reprezentace.\n",
    "    \n",
    "> **Úkoly jsou zadány tak, aby Vám daly prostor pro invenci. Vymyslet _jak přesně_ budete úkol řešit, je důležitou součástí zadání a originalita či nápaditost bude také hodnocena!**\n",
    "\n",
    "## Zdroj dat\n",
    "\n",
    "Budeme se zabývat predikcí přežití pasažérů Titaniku.\n",
    "K dispozici máte trénovací data v souboru **data.csv** a data na vyhodnocení v souboru **evaluation.csv**.\n",
    "\n",
    "#### Seznam příznaků:\n",
    "* survived - zda přežil, 0 = Ne, 1 = Ano, **vysvětlovaná proměnná**, kterou chcete predikovat\n",
    "* pclass - Třída lodního lístku, 1 = první, 2 = druhá, 3 = třetí\n",
    "* name - jméno\n",
    "* sex - pohlaví\n",
    "* age - věk v letech\n",
    "* sibsp\t- počet sourozenců / manželů, manželek na palubě\n",
    "* parch - počet rodičů / dětí na palubě\n",
    "* ticket - číslo lodního lístku\n",
    "* fare - cena lodního lístku\n",
    "* cabin\t- číslo kajuty\n",
    "* embarked\t- místo nalodění, C = Cherbourg, Q = Queenstown, S = Southampton\n",
    "* home.dest - Bydliště/Cíl\n",
    "\n",
    "## Pokyny k vypracování\n",
    "\n",
    "**Základní body zadání**, za jejichž (poctivé) vypracování získáte **8 bodů**:\n",
    "  * V Jupyter notebooku načtěte data ze souboru **data.csv**. Vhodným způsobem si je rozdělte na podmnožiny vhodné k trénování modelu.\n",
    "  * Projděte si jednotlivé příznaky a transformujte je do vhodné podoby pro použití ve vybraném klasifikačním modelu.\n",
    "  * Podle potřeby si můžete vytvářet nové příznaky (na základě existujících), například tedy můžete vytvořit příznak měřící délku jména. Některé příznaky můžete také úplně zahodit.\n",
    "  * Nějakým způsobem se vypořádejte s chybějícími hodnotami.\n",
    "  * Následně si vyberte vhodný klasifikační model z přednášek. Najděte vhodné hyperparametry a určete jeho přesnost (accuracy) na trénovací množině. Také určete jeho přesnost na testovací množině.\n",
    "  * Načtěte vyhodnocovací data ze souboru **evaluation.csv**. Napočítejte predikce pro tyto data (vysvětlovaná proměnná v nich již není). Vytvořte **results.csv** soubor, ve kterém tyto predikce uložíte do dvou sloupců: ID, predikce přežití. Tento soubor nahrajte do repozitáře.\n",
    "  * Ukázka prvních řádků souboru *results.csv*:\n",
    "  \n",
    "```\n",
    "ID,survived\n",
    "1000,0\n",
    "1001,1\n",
    "...\n",
    "```\n",
    "\n",
    "**Další body zadání** za případné další body  (můžete si vybrat, maximum bodů za úkol je každopádně 12 bodů):\n",
    "  * (až +4 body) Aplikujte všechny klasifikační modely z přednášek a určete (na základě přesnosti na validační množině), který je nejlepší. Přesnost tohoto nejlepšího modelu odhadněte pomocí křížové validace. K predikcím na vyhodnocovacích datech využijte tento model.\n",
    "  * (až +4 body) Zkuste použít nějaké (alespoň dvě) netriviální metody doplňování chybějících hodnot u věku. Zaměřte na vliv těchto metod na přesnost predikce výsledného modelu. K predikcím na vyhodnocovacích datech využijte ten přístup, který Vám vyjde jako nejlepší.\n",
    "\n",
    "## Poznámky k odevzdání\n",
    "\n",
    "  * Řiďte se pokyny ze stránky https://courses.fit.cvut.cz/BI-VZD/homeworks/index.html.\n",
    "  * Odevzdejte nejen Jupyter Notebook, ale i _csv_ soubor s predikcemi pro vyhodnocovací data (`results.csv`).\n",
    "  * Opravující Vám může umožnit úkol dodělat či opravit a získat tak další body. První verze je ale důležitá a bude-li odbytá, budete za to penalizováni**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "\n",
    "random_seed = 727"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* data si zde nactu, provedu jen deterministicke, jednoduche doplnovani chybejicich hodnot\n",
    "* slozitejsi doplneni Age probiha pote co se rozdeli na trenovaci a validacni\n",
    "* cely dataset si rozdelim na 90% + 10%\n",
    "   * 10% rezervuju na testovani\n",
    "   * 90% je pool dat pro rozdeleni pro cross validaci"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "funkce pro predpracovani dat\n",
    "* nejake sloupce jsem odstranil uplne (name, ticket, home dest) ty jsem povazoval za nepodstatne v predikci preziti\n",
    "* cabin jsem nahrail 1 pokud osoba ma kajutu, 0 pokud nema\n",
    "* fare z typu double na int jednoduchym vynasobenim\n",
    "* dle googlu se nejdrive zastavilo v Southampton, pote Cherbourg a nakonec Queenstown, proto takove poradi, ostatni (NaN jsou -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessSimple(data):\n",
    "    data = data.drop(columns = ['ticket', 'name', 'home.dest'])\n",
    "    #-----------------------------------------\n",
    "    data['sex'] = data['sex'].replace({'male': 0, 'female':1})\n",
    "    #-----------------------------------------\n",
    "    data['cabin'] = data['cabin'].fillna(-1).apply(lambda x: 1 if x != -1 else 0) #has or doesnt have a cabin\n",
    "    #-----------------------------------------\n",
    "    data['fare'] = data['fare'].fillna(0).apply(lambda x: x*10000).astype('int64')\n",
    "    #-----------------------------------------\n",
    "    data['embarked'] = data['embarked'].fillna(0).replace({'S' : 1, 'C':2, 'Q' : 3})\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = preprocessSimple(pd.read_csv(\"data.csv\").drop(columns = ['ID']))\n",
    "\n",
    "#split 90+10\n",
    "X_rest, X_test, y_rest, y_test = train_test_split(\n",
    "    data.drop(columns=['survived']), data['survived'], test_size=0.1, random_state=random_seed\n",
    ")\n",
    "\n",
    "trainData = X_rest.assign(Survived= y_rest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "k predikci preziti jsem pouzil 4 metody, kazda metoda jeste je spojena s hyperparametry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers = [(DecisionTreeClassifier, {'max_depth': range(1,101), 'criterion': ['entropy', 'gini']}),\n",
    "               (RandomForestClassifier, {'n_estimators': range(1, 100, 5), 'max_depth': range(1, 5)}),\n",
    "               (AdaBoostClassifier,  {'n_estimators': range(1,100,5), 'learning_rate': [0.01, 0.05, 0.1, 0.3, 0.5, 1]}),\n",
    "               (KNeighborsClassifier, {'n_neighbors' : range(2, 100)})]\n",
    "n_splits = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* testovani vsech modelu a jejich ruzne kombinace hyperparametru\n",
    "* validacni hodnota se bere jako prumer validacnich presnosti pomoci krizove validace\n",
    "* rozdeleni X_rest (90% dat) pomoci KFold\n",
    "* jako vysledek metody s urcitym hyperparametrem beru prumer\n",
    "* nalezeni vhodneho hyperparametru pomoci maxarg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#returns filled and scaled train dataset\n",
    "#with it also returns a function that should be used to fill and scale other datasets\n",
    "#1st scales and then fills missing values\n",
    "def transformDataFunctionCreation(method, train):\n",
    "    if method.__name__ != 'KNeighborsClassifier':\n",
    "        def scale(x):\n",
    "            return x\n",
    "    else:\n",
    "        scaler = MinMaxScaler()\n",
    "        train = pd.DataFrame(scaler.fit_transform(train),index=train.index, columns=train.columns)\n",
    "        def scale(x):\n",
    "            return pd.DataFrame(scaler.transform(x),index=x.index, columns=x.columns)\n",
    "\n",
    "    imputer = KNNImputer(n_neighbors=5, weights='distance')\n",
    "    train = pd.DataFrame(imputer.fit_transform(train),index=train.index, columns=train.columns)\n",
    "    \n",
    "    for col in train.select_dtypes('float64').columns:\n",
    "        train[col] = train[col].astype('int64')\n",
    "        \n",
    "    def transformFunction(x):\n",
    "        x = scale(x)\n",
    "        x = pd.DataFrame( imputer.transform(x),index=x.index, columns=x.columns)\n",
    "        for col in x.select_dtypes('float64').columns:\n",
    "            x[col] = x[col].astype('int64')\n",
    "        return x\n",
    "        \n",
    "    \n",
    "    return train, transformFunction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#returns mean validation of accuracy while testing 1 concrete method with 1 set of params\n",
    "#uses KFold for cross validation\n",
    "def GetValAcc(method, param, data):\n",
    "    val_p = []\n",
    "    for train, val in KFold(n_splits=n_splits).split(data.index):\n",
    "        \n",
    "        train_x = data[data.index.isin(train)].drop(columns=['Survived'])\n",
    "        train_y = data[data.index.isin(train)]['Survived']\n",
    "\n",
    "        val_x = data[data.index.isin(val)].drop(columns=['Survived'])\n",
    "        val_y = data[data.index.isin(val)]['Survived']\n",
    "        \n",
    "        #scales and fills missing values on train_x\n",
    "        #also gets a function that can be applied on validation set to fill its missing value\n",
    "        train_x, FillAndTransform = transformDataFunctionCreation(method, train_x)\n",
    "\n",
    "        dt = method(**param).fit(train_x, train_y)\n",
    "\n",
    "        #fills missing values(and scales) before predicting\n",
    "        val_x = FillAndTransform(val_x)\n",
    "        val_p.append(metrics.accuracy_score(dt.predict(val_x), val_y))\n",
    "        \n",
    "    return np.mean(val_p)\n",
    "\n",
    "\n",
    "def TestClassifier(method, p, data):\n",
    "    param_comb = ParameterGrid(p)\n",
    "    \n",
    "    #checks all values with different params using same method and calculates the best param for best value\n",
    "    val_acc = [GetValAcc(method, param, data) for param in param_comb]\n",
    "    best = np.argmax(val_acc)\n",
    "    \n",
    "    return param_comb[best], val_acc[best]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "used DecisionTreeClassifier\n",
      "{'max_depth': 3, 'criterion': 'entropy'}\n",
      "mean validation accuracy = 0.802589\n",
      "----------------------------\n",
      "used RandomForestClassifier\n",
      "{'n_estimators': 96, 'max_depth': 4}\n",
      "mean validation accuracy = 0.801514\n",
      "----------------------------\n",
      "used AdaBoostClassifier\n",
      "{'n_estimators': 11, 'learning_rate': 0.5}\n",
      "mean validation accuracy = 0.792545\n",
      "----------------------------\n",
      "used KNeighborsClassifier\n",
      "{'n_neighbors': 33}\n",
      "mean validation accuracy = 0.789088\n",
      "----------------------------\n",
      "best was DecisionTreeClassifier with {'max_depth': 3, 'criterion': 'entropy'}\n"
     ]
    }
   ],
   "source": [
    "#train + test\n",
    "#train split using KFold for cross validation\n",
    "\n",
    "bestMethod = ('', '', -1)\n",
    "\n",
    "for method, p in classifiers:\n",
    "    best_params, bestVal = TestClassifier(method, p, trainData)\n",
    "        \n",
    "    print('used', method.__name__)\n",
    "    print(best_params)\n",
    "    print('mean validation accuracy =', '{0:.6f}'.format(bestVal))\n",
    "    \n",
    "    print('----------------------------')\n",
    "    \n",
    "    if bestVal > bestMethod[2]:\n",
    "        bestMethod = (method, best_params, bestVal)\n",
    "        \n",
    "print('best was', bestMethod[0].__name__, 'with', bestMethod[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* zde uz si jen kontroluju vysledek nad test data\n",
    "* vyuzil jsem celych zbylych 90% dat k nauceni modelu a ten pak pouzil k predikci"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy on test data: 0.85\n"
     ]
    }
   ],
   "source": [
    "method = bestMethod[0]\n",
    "params = bestMethod[1]\n",
    "\n",
    "train_x, TransFunc = transformDataFunctionCreation(method, X_rest)\n",
    "test_x = TransFunc(X_test)\n",
    "\n",
    "dt = method(**params).fit(train_x, y_rest)\n",
    "print('accuracy on test data:', metrics.accuracy_score(dt.predict(test_x), y_test) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation = pd.read_csv(\"evaluation.csv\")\n",
    "IDList = evaluation['ID']\n",
    "\n",
    "evaluation = preprocessSimple(evaluation.drop(columns = ['ID']))\n",
    "evaluation = TransFunc(evaluation)\n",
    "\n",
    "res = dt.predict(evaluation)\n",
    "\n",
    "resDF = pd.DataFrame(list(zip(IDList, res)), \n",
    "               columns =['ID', 'survived'])\n",
    "resDF.to_csv(r'result.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
